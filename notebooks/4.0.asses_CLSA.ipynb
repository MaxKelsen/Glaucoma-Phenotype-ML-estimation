{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assesing how the model compares with clinician rater on CLSA data\n",
    "\n",
    "This file is part of the Glaucoma Phenotype ML Estimation project.\n",
    "\n",
    " Glaucoma Phenotype ML Estimation is free software: you can redistribute it and/or modify\n",
    "it under the terms of the GNU General Public License as published by\n",
    "the Free Software Foundation, either version 3 of the License, or\n",
    "(at your option) any later version.\n",
    "\n",
    "\n",
    "The Glaucoma Phenotype ML Estimation project is distributed in the hope that it will be useful,\n",
    "but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "GNU General Public License for more details.\n",
    "\n",
    "You should have received a copy of the GNU General Public License\n",
    "along with the Glaucoma Phenotype ML Estimation project.  If not, see <http://www.gnu.org/licenses/>.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some data from the CLSA was graded by a clinican to compare to the models performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "from pathlib import Path\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "#import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from fastai.vision import *\n",
    "from IPython.display import display\n",
    "\n",
    "from multiprocessing import freeze_support\n",
    "from multiprocessing import Pool\n",
    "from multiprocessing import cpu_count\n",
    "from functools import partial\n",
    "import threading\n",
    "\n",
    "from fastai.vision import *\n",
    "from fastai.vision.models import *\n",
    "from fastai.vision.learner import model_meta\n",
    "from fastai.callbacks import *\n",
    "from PIL import Image\n",
    "from glaucoma.helpers.glaucoma_helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### PLEASE SET AS REQUIRED########\n",
    "WORKING_DIR = Path(os.getcwd())\n",
    "DATA_DIR = WORKING_DIR / 'data'\n",
    "META_DIR = DATA_DIR / 'metadata'\n",
    "TRAIN_DIR = DATA_DIR / 'train'\n",
    "UKBB_DIR = DATA_DIR 'retinal_images/UKBB'\n",
    "CROP_DIR = DATA_DIR /'retinal_images/cropped_UKBB')\n",
    "C_CLSA_DIR = DATA_DIR / 'retinal_images/cropped_CLSA')\n",
    "GRADE_DIR = DATA_DIR / \"gradable\"\n",
    "CLSA_DIR =DATA_DIR / 'retinal_images/CLSA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLSA_preds = pd.read_csv(WORKING_DIR /'inference/CLSA_full_inference_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLSA_clin = pd.read_csv('/home/jovyan/glaucoma/set_xaa_alexhewitt.VCDR',sep = '\\t',header = None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>190225_QIMR_SMacGregor_1000258_left.jpg</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>190225_QIMR_SMacGregor_1000551_left.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>190225_QIMR_SMacGregor_1000651_left.jpg</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         0    1\n",
       "0  190225_QIMR_SMacGregor_1000258_left.jpg  3.5\n",
       "1  190225_QIMR_SMacGregor_1000551_left.jpg    3\n",
       "2  190225_QIMR_SMacGregor_1000651_left.jpg  2.5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLSA_clin.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull out relevant preds:\n",
    "files = CLSA_clin[0]\n",
    "ratings  =CLSA_clin[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_preds = CLSA_preds[CLSA_preds['file_name'].isin(files)]\n",
    "used_preds = used_preds[used_preds['follow_up'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting error between clincian and model\n",
    "error = []\n",
    "mse = []\n",
    "error_file = {}\n",
    "X =[]\n",
    "Y =[]\n",
    "gradabillity ={}\n",
    "for i in files:\n",
    "    if CLSA_clin[CLSA_clin[0] == i][1].item() != 'X':\n",
    "        e = np.abs(used_preds[used_preds['file_name'] == i]['vcdr_estimate'].item() - float(CLSA_clin[CLSA_clin[0] == i][1].item()))\n",
    "        error.append(e)\n",
    "        mse.append(np.power(used_preds[used_preds['file_name'] == i]['vcdr_estimate'].item() - float(CLSA_clin[CLSA_clin[0] == i][1].item()),2))\n",
    "        X.append(used_preds[used_preds['file_name'] == i]['vcdr_estimate'].item())\n",
    "        Y.append(float(CLSA_clin[CLSA_clin[0] == i][1].item()))\n",
    "    else:\n",
    "        gradabillity[i] = used_preds[used_preds['file_name'] == i]['gradable'].item()\n",
    "        \n",
    "X = np.asarray(X)\n",
    "Y = np.asarray(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0991911148179758"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# root mean square error\n",
    "np.sqrt(np.average(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = np.corrcoef(X, Y)\n",
    "correlation_xy = correlation_matrix[0,1]\n",
    "r_squared = correlation_xy**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8394766459101302"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#correlation between clinican and modek\n",
    "correlation_xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff = parse_files(C_CLSA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_name ='190225_QIMR_SMacGregor_1266754_left.jpg'\n",
    "im = [i for i in ff if f_name in i and 'followup' in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "#img=mpimg.imread(ukbb_images_right[0])\n",
    "im = Image.open(im[0])\n",
    "imgplot = plt.imshow(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "#from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.2510593220338983\n"
     ]
    }
   ],
   "source": [
    "y_hat, y= categorical_convert_metrics([torch.tensor(X).view([-1,1]),torch.tensor(Y).view([1,-1]).t()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# approx rating\n",
    "pm_thres = 2.01\n",
    "correct = 0\n",
    "for i,truth in enumerate(Y):\n",
    "    if y_hat[i] > truth - pm_thres and y_hat[i] < truth + pm_thres:\n",
    "        correct +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9290254237288136"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#percent within 2 grading points of CLSA model\n",
    "correct/944"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Glaucoma",
   "language": "python",
   "name": "glaucoma"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}