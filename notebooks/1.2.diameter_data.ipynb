{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diameter Data\n",
    "\n",
    "This file is part of the Glaucoma Phenotype ML Estimation project.\n",
    "\n",
    " Glaucoma Phenotype ML Estimation is free software: you can redistribute it and/or modify\n",
    "it under the terms of the GNU General Public License as published by\n",
    "the Free Software Foundation, either version 3 of the License, or\n",
    "(at your option) any later version.\n",
    "\n",
    "\n",
    "The Glaucoma Phenotype ML Estimation project is distributed in the hope that it will be useful,\n",
    "but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "GNU General Public License for more details.\n",
    "\n",
    "You should have received a copy of the GNU General Public License\n",
    "along with the Glaucoma Phenotype ML Estimation project.  If not, see <http://www.gnu.org/licenses/>.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pickle as pkl\n",
    "import os\n",
    "from pathlib import Path\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "#import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from fastai.vision import *\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "from multiprocessing import freeze_support\n",
    "from multiprocessing import Pool\n",
    "from multiprocessing import cpu_count\n",
    "from functools import partial\n",
    "import threading\n",
    "sys.setrecursionlimit(5000)\n",
    "from fastai.distributed import *\n",
    "from glaucoma.helpers.glaucoma_helpers import is_number, parse_files, return_uniq_index, return_duplicates, plot_idx, split_unzipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split up unzipped files\n",
    "unzipped_head, unzipped_tail = split_unzipped(unzipped_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "unzipped_check = [unzipped_head[i] +\"/\"+unzipped_tail[i] for i in range(len(unzipped_head))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### PLEASE SET AS REQUIRED########\n",
    "WORKING_DIR = Path(os.getcwd())\n",
    "DATA_DIR = WORKING_DIR / 'data'\n",
    "META_DIR = DATA_DIR / 'metadata'\n",
    "TRAIN_DIR =DATA_DIR / \"train\"\n",
    "UKBB_DIR = DATA_DIR / 'retinal_images/UKBB'\n",
    "CROP_DIR = DATA_DIR/'retinal_images/cropped_UKBB'\n",
    "UNZIPPED_DIR = DATA_DIR / 'unzipped'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncropped_full = parse_files(UKBB_DIR)\n",
    "uncropped_split = [os.path.split(f) for f in uncropped_full]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncropped_dict = { h[1]:h[0] for h in uncropped_split}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_df = pd.read_csv(UKBB_DIR / 'clinical_gradings' / 'df_VCDR_DISC_grade_result_merge_2020_July_15_chunk_1_50_71_88 - df_VCDR_DISC_grade_result_merge_2020_July_15_chunk_1_50_71_88.csv.csv'  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "v2_meta_df = pkl.load(open(WORKING_DIR / 'v2_meta_df.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "v2_meta_df[[\"coord1\",\"coord2\"]] = v2_meta_df.area.str.split(\":\",expand = True).loc[:,0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at diameter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_radius(p1, p2):\n",
    "    if isinstance(p1,str):\n",
    "        p1 = tuple(map(int,p1.split(\",\")))\n",
    "    if isinstance(p2,str):\n",
    "        p2 = tuple(map(int,p2.split(\",\")))\n",
    "    r2 = np.power(p2[0]- p1[0],2) + np.power(p2[1] - p1[1],2)\n",
    "    return np.sqrt(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#original size = (2048, 1536)\n",
    "def diameter_visualise(file_path ,coord1, coord2, uncropped = False):\n",
    "    #pull uncrooped \n",
    "    if uncropped:\n",
    "        h,t = os.path.split(file_path)\n",
    "        t = t[:-4] + \".png\"\n",
    "        file_path = uncropped_dict[t] +\"/\" + t\n",
    "        \n",
    "    \n",
    "    im = plt.imread(file_path)\n",
    "    implot = plt.imshow(im,origin = \"upper\")\n",
    "    print(\"coord 1:\" +str(coord1) +\" coord 2:\" +str(coord2) )\n",
    "    #plot points\n",
    "    x_len = im.shape[1]\n",
    "    y_len = im.shape[0]\n",
    "\n",
    "    print(x_len, y_len)\n",
    "    #x_r =  x_len * (1 +12/770) /  770\n",
    "    #y_r = (y_len / (583)) *6/5 \n",
    "    \n",
    "    x_r = x_len / 665\n",
    "    y_r =y_len / float(665 / 1.35)\n",
    "    x_shift = 0\n",
    "       \n",
    "    \n",
    "    x1 =  (coord1[0] + x_shift ) * x_r \n",
    "    x2 =  (coord2[0] + x_shift) * x_r \n",
    "    \n",
    "    y1 = (coord1[1] ) * y_r \n",
    "    y2 = (coord2[1]) * y_r \n",
    "    \n",
    "    points =[[ x_len -x1,x_len- x2],[y1,y2]]\n",
    "    points2 =[[x1,x2],[y1,y2]]\n",
    "    points3 =[[x1,x2],[y_len-y1,y_len -y2]]\n",
    "    points4 =[[x_len -x1,x_len - x2],[y_len - y1,y_len - y2]]\n",
    "\n",
    "    plt.scatter(*points2)\n",
    "    plt.plot(*points2,\"b\")\n",
    "    #plt.plot(*points3)\n",
    "    #plt.plot(*points4)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v2_meta_df[v2_meta_df['file_name'] == '1021701_21015_0_0.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_num(num):\n",
    "    key = v2_meta_df.loc[num,:]\n",
    "    idx = unzipped_tail.index(key[\"file_name\"])\n",
    "    print(key)\n",
    "    im = diameter_visualise(unzipped_files[idx],tuple(map(int,key[\"coord1\"].split(\",\"))),tuple(map(int,key[\"coord2\"].split(\",\"))), False)\n",
    "\n",
    "#idx = unzipped_tail.index('4821158_21015_0_0.jpg')\n",
    "#im = diameter_visualise(unzipped_files[idx],(222,186),(218,331))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v2_meta_df[v2_meta_df['file_name'] == '4969460_21015_0_0.jpg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## building model with point data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_only = [f for f in list(v2_meta_df['batch_name'].unique()) if f[0] == 'L']\n",
    "r = re.compile(\"L_[1-9][1-9]_\")\n",
    "L_only = list(filter(r.match, L_only)) # Read Note\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function rescales the diameter points into the correct pixel coordinates, an artifact from the labeling program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_coord(image, p):\n",
    "    #idx = unzipped_tail.index(image)\n",
    "    #im = plt.imread(unzipped_files[idx])\n",
    "    #x_len = im.shape[1]\n",
    "    #y_len = im.shape[0]\n",
    "    \n",
    "    x_len, y_len = 1040, 800\n",
    "    p = tuple(map(int,p.split(\",\")))\n",
    "    \n",
    "    x_r =  x_len /665\n",
    "    y_r = (y_len / (665/1.35))\n",
    "    \n",
    "    x_scaled = int(np.round(p[0] * x_r))\n",
    "    y_scaled = int(np.round(p[1] * y_r))\n",
    "    \n",
    "    return (x_scaled,y_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "v2_used = v2_meta_df[v2_meta_df['batch_name'].isin(L_only)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the rescaled coordinates\n",
    "v2_used['coord1_rs'] = v2_used.apply(lambda x: rescale_coord(x.file_name, x.coord1), axis=1)\n",
    "v2_used['coord2_rs'] = v2_used.apply(lambda x: rescale_coord(x.file_name, x.coord2), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the method for getting points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove ungraded imaiges\n",
    "v2_graded = v2_used[~v2_used.coord1.str.contains('-1') ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#move all gradable images across\n",
    "for f_name in v2_graded['file_name']:\n",
    "    idx = unzipped_tail.index(f_name)\n",
    "    f = unzipped_files[idx]\n",
    "    shutil.copy(f, DATA_DIR / 'diameter' /f_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coord_str_tup(string):\n",
    "    return(tuple(map(int,string.split(','))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_coords(df):\n",
    "    coords1 = [[],[]]\n",
    "    coords2 = [[],[]]\n",
    "    for coord in df['coord1_rs']:\n",
    "        tup = coord\n",
    "        coords1[0].append(tup[0])\n",
    "        coords1[1].append(tup[1])\n",
    "    \n",
    "    for coord in df['coord2_rs']:\n",
    "        tup = coord\n",
    "        coords2[0].append(tup[0])\n",
    "        coords2[1].append(tup[1])\n",
    "        \n",
    "    return [(int(np.round(np.average(coords1[0]))),int(np.round(np.average(coords1[1])))),(int(np.round(np.average(coords2[0]))),int(np.round(np.average(coords2[1]))))]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coords(o):\n",
    "    h , t = os.path.split(o)\n",
    "    #print(v2_meta_df[v2_meta_df['file_name'] == t]['coord1'])\n",
    "    #check size:\n",
    "    if v2_graded[v2_graded['file_name'] == t]['coord1_rs'].shape[0]  > 1:\n",
    "        #average the coordinates:\n",
    "        print(v2_graded[v2_graded['file_name'] == t]['coord1_rs'])\n",
    "        res = average_coords(v2_graded[v2_graded['file_name'] == t])\n",
    "        return torch.tensor([[res[0][1],res[0][0]], [res[1][1],res[1][0]]] )\n",
    "        \n",
    "    c1 = v2_graded[v2_graded['file_name'] == t]['coord1_rs'].item()\n",
    "    c2 = v2_graded[v2_graded['file_name'] == t]['coord2_rs'].item()\n",
    " \n",
    "    #fast ai expects a format of y, x\n",
    "    return torch.tensor([[c1[1],c1[0]],[c2[1],c2[0]] ])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "diameter_files = parse_files(DATA_DIR / 'diameter')\n",
    "diameter_files = [os.path.basename(f) for f in diameter_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_dict = { o:get_coords(o) for o in diameter_files}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(coord_dict, open(WORKING_DIR / 'coord_dict.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_pnt(o):\n",
    "    h , t = os.path.split(o)\n",
    "    return coord_dict[t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = (PointsItemList.from_folder(DATA_DIR / 'diameter')).split_by_rand_pct(seed=42).label_from_func(get_label_pnt)\n",
    "tfms = get_transforms(max_lighting = 0.25)\n",
    "size= (800,1040)\n",
    "data = src.transform(tfms=tfms,tfm_y = True, size=size, resize_method=ResizeMethod.SQUISH).databunch(num_workers=num_cpu).normalize(imagenet_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(data,models.resnet34, pretrained = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSELossFlat(nn.MSELoss): \n",
    "#“Same as `nn.MSELoss`, but flattens input and target.”\n",
    "    def forward(self, input:Tensor, target:Tensor) -> Rank0Tensor:\n",
    "        return super().forward(input.view(-1), target.view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.data.batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## building model with just diamater data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some other stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_columns = ['DISC_visit_0_mean','DISC_visit_1_mean']\n",
    "disc_df = uk_df[(~np.isnan(uk_df[disc_columns[0]])) | (~np.isnan(uk_df[disc_columns[1]]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_image =[]\n",
    "for fid in disc_df['FID']:\n",
    "    if len(parse_files(UNZIPPED_DIR,str(fid))) > 1:\n",
    "        multi_image.append(fid)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "right = [f for f in list(v2_meta_df['file_name']) if '21016' in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_list = parse_files(UNZIPPED_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_names = [f[-21:] for f in f_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "fids = list(disc_df['FID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "v2_meta_df['radius'] = v2_meta_df.apply(lambda x: cal_radius(x.coord1, x.coord2), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "v2_graded = v2_meta_df[v2_meta_df['radius'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "v2_graded_average  = v2_graded.groupby('file_name').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff = parse_files(UNZIPPED_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104342"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in ff:\n",
    "    shutil.copy(f, DATA_DIR / 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_img = UNZIPPED_DIR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "path_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "v2_graded_average.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = ImageList.from_df(v2_graded_average, path = DATA_DIR / \"all\").split_by_rand_pct(seed=42).label_from_df(label_cls=FloatList)\n",
    "tfms = get_transforms(max_lighting = 0.25) # or tfms=None if none are needed\n",
    "size= (800,1040) # size=(224,224) or (400,224)\n",
    "data = src.transform(tfms=tfms, size=size, resize_method=ResizeMethod.SQUISH).databunch(num_workers=num_cpu).normalize(imagenet_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSELossFlat(nn.MSELoss): \n",
    "#“Same as `nn.MSELoss`, but flattens input and target.”\n",
    "    def forward(self, input:Tensor, target:Tensor) -> Rank0Tensor:\n",
    "        return super().forward(input.view(-1), target.view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.data.batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class L1LossFlat(nn.L1Loss):\n",
    "#Mean Absolute Error Loss”\n",
    "    def forward(self, input:Tensor, target:Tensor) -> Rank0Tensor:\n",
    "        return super().forward(input.view(-1), target.view(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing cropping old\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "ukbb_image_folders_left =[\n",
    " 'raw_image_21015_0_0_png',\n",
    " 'raw_image_21015_0_1_png',\n",
    " 'raw_image_21015_1_0_png',\n",
    "]\n",
    "\n",
    "ukbb_image_folders_right =[\n",
    "'raw_image_21016_1_0_png',\n",
    " 'raw_image_21016_0_0_png',\n",
    " 'raw_image_21016_0_1_png']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ukbb_images_left = {dir_name:parse_files(UKBB_DIR / dir_name) for dir_name in ukbb_image_folders_left}\n",
    "ukbb_images_right = {dir_name:parse_files(UKBB_DIR / dir_name) for dir_name in ukbb_image_folders_right}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_files = parse_files(CROP_DIR / 'crop_image_21016_0_1_png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'raw_image_21016_0_1_png'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ukbb_image_folders_right[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 686/686 [00:00<00:00, 305932.22it/s]\n"
     ]
    }
   ],
   "source": [
    "#rightimages left = 800, left images: left = 350\n",
    "left = 800\n",
    "top = 350\n",
    "right = 1040 + left\n",
    "bottom = 800 +top\n",
    "save_path = CROP_DIR / 'crop_image_21016_0_1_png'\n",
    "crop_files(ukbb_images_right[ukbb_image_folders_right[2]],(left,top,right,bottom),save_path, num_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "686"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## delete all files not supposed to be in\n",
    "list_files_0_1 = parse_files(CROP_DIR / 'crop_image_21015_0_1_png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Glaucoma",
   "language": "python",
   "name": "glaucoma"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
